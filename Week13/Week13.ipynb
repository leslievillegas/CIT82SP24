{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2G3Bzq7HRLl"
      },
      "source": [
        "# Week 13 Neural Networks using Sci-kit learn and Keras\n",
        "This week you will fit a regression model using a neural network model.  You will compare the Sc-kit learn MLPRegressor and Keras neural network.\n",
        "\n",
        "Run the code cell below to include the libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FDSZuGEzo7n8"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_selector, make_column_transformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjr0Z5Q7HzPF"
      },
      "source": [
        "# Load the Dataset\n",
        "The code below will allow you to import the dataset from the University of California, Irvine data repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbklo11-IZIr",
        "outputId": "b0242a0f-c42c-4c9e-ceeb-face9b31b3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh6EDl4UIZVX",
        "outputId": "49dd2ab5-1f6e-4ebb-8bd8-ef4f104d59eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     name     role        type demographic  \\\n",
            "0                                      No       ID     Integer        None   \n",
            "1                     X1 transaction date  Feature  Continuous        None   \n",
            "2                            X2 house age  Feature  Continuous        None   \n",
            "3  X3 distance to the nearest MRT station  Feature  Continuous        None   \n",
            "4         X4 number of convenience stores  Feature     Integer        None   \n",
            "5                             X5 latitude  Feature  Continuous        None   \n",
            "6                            X6 longitude  Feature  Continuous        None   \n",
            "7              Y house price of unit area   Target  Continuous        None   \n",
            "\n",
            "                                         description  \\\n",
            "0                                               None   \n",
            "1  for example, 2013.250=2013 March, 2013.500=201...   \n",
            "2                                               None   \n",
            "3                                               None   \n",
            "4  number of convenience stores in the living cir...   \n",
            "5                    geographic coordinate, latitude   \n",
            "6                   geographic coordinate, longitude   \n",
            "7  10000 New Taiwan Dollar/Ping, where Ping is a ...   \n",
            "\n",
            "                          units missing_values  \n",
            "0                          None             no  \n",
            "1                          None             no  \n",
            "2                          year             no  \n",
            "3                         meter             no  \n",
            "4                       integer             no  \n",
            "5                        degree             no  \n",
            "6                        degree             no  \n",
            "7  10000 New Taiwan Dollar/Ping             no  \n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "df = fetch_ucirepo(id=477)\n",
        "\n",
        "RealEstate = pd.concat([df.data.features, df.data.targets], axis=1)\n",
        "\n",
        "# variable information\n",
        "print(df.variables)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "420TiEy5rfiy",
        "outputId": "bc92befe-529c-4377-953f-a0993c1f8106"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   X1 transaction date  X2 house age  X3 distance to the nearest MRT station  \\\n",
              "0             2012.917          32.0                                84.87882   \n",
              "1             2012.917          19.5                               306.59470   \n",
              "2             2013.583          13.3                               561.98450   \n",
              "3             2013.500          13.3                               561.98450   \n",
              "4             2012.833           5.0                               390.56840   \n",
              "\n",
              "   X4 number of convenience stores  X5 latitude  X6 longitude  \\\n",
              "0                               10     24.98298     121.54024   \n",
              "1                                9     24.98034     121.53951   \n",
              "2                                5     24.98746     121.54391   \n",
              "3                                5     24.98746     121.54391   \n",
              "4                                5     24.97937     121.54245   \n",
              "\n",
              "   Y house price of unit area  \n",
              "0                        37.9  \n",
              "1                        42.2  \n",
              "2                        47.3  \n",
              "3                        54.8  \n",
              "4                        43.1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-083254fa-0adc-4a70-8d1c-0c125a6a325c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1 transaction date</th>\n",
              "      <th>X2 house age</th>\n",
              "      <th>X3 distance to the nearest MRT station</th>\n",
              "      <th>X4 number of convenience stores</th>\n",
              "      <th>X5 latitude</th>\n",
              "      <th>X6 longitude</th>\n",
              "      <th>Y house price of unit area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012.917</td>\n",
              "      <td>32.0</td>\n",
              "      <td>84.87882</td>\n",
              "      <td>10</td>\n",
              "      <td>24.98298</td>\n",
              "      <td>121.54024</td>\n",
              "      <td>37.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012.917</td>\n",
              "      <td>19.5</td>\n",
              "      <td>306.59470</td>\n",
              "      <td>9</td>\n",
              "      <td>24.98034</td>\n",
              "      <td>121.53951</td>\n",
              "      <td>42.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013.583</td>\n",
              "      <td>13.3</td>\n",
              "      <td>561.98450</td>\n",
              "      <td>5</td>\n",
              "      <td>24.98746</td>\n",
              "      <td>121.54391</td>\n",
              "      <td>47.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013.500</td>\n",
              "      <td>13.3</td>\n",
              "      <td>561.98450</td>\n",
              "      <td>5</td>\n",
              "      <td>24.98746</td>\n",
              "      <td>121.54391</td>\n",
              "      <td>54.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012.833</td>\n",
              "      <td>5.0</td>\n",
              "      <td>390.56840</td>\n",
              "      <td>5</td>\n",
              "      <td>24.97937</td>\n",
              "      <td>121.54245</td>\n",
              "      <td>43.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-083254fa-0adc-4a70-8d1c-0c125a6a325c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-083254fa-0adc-4a70-8d1c-0c125a6a325c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-083254fa-0adc-4a70-8d1c-0c125a6a325c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a29ee6d5-d3b7-4aef-a84a-2a82407d89b8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a29ee6d5-d3b7-4aef-a84a-2a82407d89b8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a29ee6d5-d3b7-4aef-a84a-2a82407d89b8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "RealEstate",
              "summary": "{\n  \"name\": \"RealEstate\",\n  \"rows\": 414,\n  \"fields\": [\n    {\n      \"column\": \"X1 transaction date\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2819672402630118,\n        \"min\": 2012.667,\n        \"max\": 2013.583,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2013.0,\n          2012.75,\n          2012.917\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X2 house age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.392484533242536,\n        \"min\": 0.0,\n        \"max\": 43.8,\n        \"num_unique_values\": 236,\n        \"samples\": [\n          38.2,\n          3.4,\n          27.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X3 distance to the nearest MRT station\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1262.1095954078514,\n        \"min\": 23.38284,\n        \"max\": 6488.021,\n        \"num_unique_values\": 259,\n        \"samples\": [\n          552.4371,\n          4605.749,\n          405.2134\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X4 number of convenience stores\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          6,\n          10,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X5 latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012410196590450335,\n        \"min\": 24.93207,\n        \"max\": 25.01459,\n        \"num_unique_values\": 234,\n        \"samples\": [\n          24.98573,\n          24.96143,\n          24.96696\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X6 longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015347183004592205,\n        \"min\": 121.47353,\n        \"max\": 121.56627,\n        \"num_unique_values\": 232,\n        \"samples\": [\n          121.54634,\n          121.50831,\n          121.53372\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y house price of unit area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.606487697735314,\n        \"min\": 7.6,\n        \"max\": 117.5,\n        \"num_unique_values\": 270,\n        \"samples\": [\n          25.0,\n          30.7,\n          18.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "RealEstate.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpbPETROxUGB"
      },
      "source": [
        "# Input and output features & split into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BIy84NHSr6Av"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(RealEstate, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t6hoeKG7sXzn"
      },
      "outputs": [],
      "source": [
        "y = train[\"Y house price of unit area\"]\n",
        "X = train.drop(\"Y house price of unit area\", axis=1)\n",
        "y_test = test['Y house price of unit area']\n",
        "X_test = test.drop('Y house price of unit area', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_kgtIqQM7FTD"
      },
      "outputs": [],
      "source": [
        "# Numeric pipeline\n",
        "num_feature = X.select_dtypes(np.number).columns\n",
        "numeric_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G1nGdlQ87KTL"
      },
      "outputs": [],
      "source": [
        "# Categorical pipeline\n",
        "cat_feature = X.select_dtypes(include=['object']).columns\n",
        "categorical_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='most_frequent'),\n",
        "    OneHotEncoder(handle_unknown='ignore')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oNk5ii487Fc4"
      },
      "outputs": [],
      "source": [
        "# Preprocessor\n",
        "preprocessing_pipeline = ColumnTransformer([\n",
        "    ('numeric', numeric_pipeline, num_feature),\n",
        "    ('categorical', categorical_pipeline, cat_feature)\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6HZhjV9Krks"
      },
      "source": [
        "# Create a Neural Network\n",
        "It is now time to create the neural network in a pipeline.\n",
        "\n",
        "```\n",
        "neural_pip = Pipeline([\n",
        "    ('preprocessing', preprocess_pipeline),\n",
        "    ('neural', MLPRegressor(., ., .)\n",
        "])\n",
        "\n",
        "neural_pip.fix(X_training, y_training)\n",
        "\n",
        "y_p = neural_pip.predict(X_testing)\n",
        "\n",
        "print(\"MSE: \", mean_square_error(y_test, y_p))\n",
        "print(\"MAE: \", mean_absolute_error(y_test, y_p))\n",
        "\n",
        "```\n",
        "\n",
        "# Question 1\n",
        "Use the code above to do  the following:\n",
        "1. Create the pipeline for the Neural Network called nn_pipeline.  Include the preprocess_pipeline call it 'preprocessing'.  Create the MLPRegressor and call it 'nn'.  The parameters for the MLPRegressor are max_iter=300, activation ='relu', hidden_layer_sizes=(100, 100).\n",
        "2. Fit the nn_pipeline with the training features X and target variable y.\n",
        "3. Predict the y values using X_test call it y_pred.\n",
        "4. Print out MSE using mean_squared_error(y_test, y_pred).\n",
        "5. Print out MAE using mean_absolute_error(y_test, y_pred)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "buXsrR-HO6P6"
      },
      "outputs": [],
      "source": [
        "# Question 1 - 1) (Do not remove)\n",
        "nn_pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessing_pipeline),\n",
        "    ('nn', MLPRegressor(max_iter=300, activation='relu', hidden_layer_sizes=(100, 100)))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tXJ23ivrO6fu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3321734b-e0fc-4f36-97a5-b0bf2d3f6062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 40.99730735391726\n",
            "MAE: 4.610771413096576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Question 1 - 2 thru 5)  (Do not remove)\n",
        "\n",
        "# 2\n",
        "nn_pipeline.fit(X, y)\n",
        "\n",
        "# 3\n",
        "y_pred = nn_pipeline.predict(X_test)\n",
        "\n",
        "# 4 & 5\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws8rvgz5yv2n"
      },
      "source": [
        "# 2. Keras neural network\n",
        "Keras is not Sci-kit learn library.  It is built on TensorFlow.\n",
        "\n",
        "```\n",
        "trans_x = preprocessing_pipeline.fit_transform(X_train)\n",
        "\n",
        "md = Sequential()\n",
        "md.add(Dense(., input_dim= X_train.shape[1], activation='.'))\n",
        "md.add(Dense(., activation='. '))\n",
        "md.add(Dense(1))\n",
        "\n",
        "md.compile(loss=., optimizer=keras.optimizers.Adam(learning_rate=., metrics=[' '])\n",
        "\n",
        "history = md.fit(trans_x, y, epochs=.)\n",
        "```\n",
        "\n",
        "# Question 2\n",
        "Use the code above to do the following:\n",
        "1. Preprocess the X_train which is X.  Assign the preprocess training X in a variable X_trans.\n",
        "2. Create a model called model instead of md.  In the first Dense 100, input_dim=X.shape[1], activation='relu'))\n",
        "3. Create a model called model instead of md with a Dense layer with 100, activation='relu'.\n",
        "4. Create the last Dense layer of 1.\n",
        "5. Create model.compile with parameters loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.001), and metrics=['mae'])\n",
        "6. Display the loss and metric call it history by model.fit(the transformed X training and y with epochs = 300.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tKd5UToLULXn"
      },
      "outputs": [],
      "source": [
        "# Question 2  - 1) ( Do not remove)\n",
        "X_trans = preprocessing_pipeline.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6wYgccarULeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d70665-526f-497b-dada-db51250646b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1616.2072 - mae: 37.7477\n",
            "Epoch 2/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1564.0522 - mae: 36.5270 \n",
            "Epoch 3/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1463.2423 - mae: 35.3556 \n",
            "Epoch 4/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1242.1041 - mae: 32.7626 \n",
            "Epoch 5/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 959.2517 - mae: 27.8095 \n",
            "Epoch 6/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 754.2572 - mae: 24.2312 \n",
            "Epoch 7/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 521.0305 - mae: 19.9351 \n",
            "Epoch 8/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 246.1295 - mae: 12.8278 \n",
            "Epoch 9/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 175.3074 - mae: 9.7460  \n",
            "Epoch 10/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 94.0804 - mae: 7.9215  \n",
            "Epoch 11/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.0896 - mae: 7.4950\n",
            "Epoch 12/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 81.4138 - mae: 7.1038  \n",
            "Epoch 13/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 70.4019 - mae: 6.3606  \n",
            "Epoch 14/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 76.7171 - mae: 6.6449  \n",
            "Epoch 15/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 66.8652 - mae: 6.2853  \n",
            "Epoch 16/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 85.7156 - mae: 6.5944 \n",
            "Epoch 17/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 74.1687 - mae: 5.9215  \n",
            "Epoch 18/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 83.8417 - mae: 6.2597 \n",
            "Epoch 19/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 75.4433 - mae: 6.1217 \n",
            "Epoch 20/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.5882 - mae: 5.8527 \n",
            "Epoch 21/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.0713 - mae: 5.6270 \n",
            "Epoch 22/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 65.8794 - mae: 5.7630 \n",
            "Epoch 23/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 67.5985 - mae: 5.9901 \n",
            "Epoch 24/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.3997 - mae: 5.7273 \n",
            "Epoch 25/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.4341 - mae: 5.8174 \n",
            "Epoch 26/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 52.1529 - mae: 5.4688  \n",
            "Epoch 27/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.5906 - mae: 5.3821  \n",
            "Epoch 28/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 66.6972 - mae: 6.0269 \n",
            "Epoch 29/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 77.3169 - mae: 5.9142 \n",
            "Epoch 30/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 73.9010 - mae: 6.0275  \n",
            "Epoch 31/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 53.5792 - mae: 5.5596 \n",
            "Epoch 32/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.2062 - mae: 5.3044 \n",
            "Epoch 33/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 53.4021 - mae: 5.2612  \n",
            "Epoch 34/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 52.6551 - mae: 5.2824 \n",
            "Epoch 35/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.7582 - mae: 5.5933 \n",
            "Epoch 36/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 74.9982 - mae: 5.8276 \n",
            "Epoch 37/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.1783 - mae: 5.4267 \n",
            "Epoch 38/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 71.4734 - mae: 5.4104 \n",
            "Epoch 39/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 71.2415 - mae: 5.7379 \n",
            "Epoch 40/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 85.9186 - mae: 5.7676  \n",
            "Epoch 41/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 74.9580 - mae: 5.6308  \n",
            "Epoch 42/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.5594 - mae: 5.4929 \n",
            "Epoch 43/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.9491 - mae: 5.2950 \n",
            "Epoch 44/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.2784 - mae: 5.0359 \n",
            "Epoch 45/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.0760 - mae: 5.4909 \n",
            "Epoch 46/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.8041 - mae: 5.2558 \n",
            "Epoch 47/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 67.7581 - mae: 5.5759  \n",
            "Epoch 48/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.7464 - mae: 5.2548 \n",
            "Epoch 49/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.4823 - mae: 4.7273 \n",
            "Epoch 50/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 71.0147 - mae: 5.7583 \n",
            "Epoch 51/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.1113 - mae: 5.5680 \n",
            "Epoch 52/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 73.4011 - mae: 5.6033 \n",
            "Epoch 53/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.6474 - mae: 5.1365 \n",
            "Epoch 54/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 64.7864 - mae: 5.5836 \n",
            "Epoch 55/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.3013 - mae: 5.3201 \n",
            "Epoch 56/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 79.2194 - mae: 5.3909  \n",
            "Epoch 57/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.8231 - mae: 5.1348  \n",
            "Epoch 58/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 62.3750 - mae: 5.3944 \n",
            "Epoch 59/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.5882 - mae: 4.9674 \n",
            "Epoch 60/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 69.0077 - mae: 5.2032 \n",
            "Epoch 61/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 53.7263 - mae: 5.0303 \n",
            "Epoch 62/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 52.2676 - mae: 5.2247 \n",
            "Epoch 63/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 82.8988 - mae: 5.5255  \n",
            "Epoch 64/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 69.1966 - mae: 5.3179 \n",
            "Epoch 65/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.6649 - mae: 4.7791  \n",
            "Epoch 66/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.9448 - mae: 5.3837  \n",
            "Epoch 67/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.8941 - mae: 5.0798 \n",
            "Epoch 68/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.5294 - mae: 5.0247 \n",
            "Epoch 69/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.4558 - mae: 5.2291 \n",
            "Epoch 70/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.2477 - mae: 5.0343  \n",
            "Epoch 71/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 52.4702 - mae: 5.1772 \n",
            "Epoch 72/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 77.5619 - mae: 5.3394  \n",
            "Epoch 73/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.6278 - mae: 4.8402 \n",
            "Epoch 74/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49.0194 - mae: 5.0791 \n",
            "Epoch 75/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.3631 - mae: 4.8647 \n",
            "Epoch 76/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.0737 - mae: 5.0730 \n",
            "Epoch 77/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.1177 - mae: 4.6595 \n",
            "Epoch 78/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.1558 - mae: 4.9910 \n",
            "Epoch 79/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.7721 - mae: 4.8729 \n",
            "Epoch 80/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49.1643 - mae: 4.6928 \n",
            "Epoch 81/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55.0422 - mae: 4.8072 \n",
            "Epoch 82/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 68.8832 - mae: 5.3606  \n",
            "Epoch 83/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 68.9582 - mae: 5.2992 \n",
            "Epoch 84/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 64.3767 - mae: 5.1174 \n",
            "Epoch 85/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 81.7570 - mae: 5.3617  \n",
            "Epoch 86/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.6166 - mae: 4.8635 \n",
            "Epoch 87/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.0911 - mae: 4.8529 \n",
            "Epoch 88/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 52.5995 - mae: 4.9388 \n",
            "Epoch 89/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.7499 - mae: 4.7195 \n",
            "Epoch 90/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55.8358 - mae: 4.9642  \n",
            "Epoch 91/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 82.2382 - mae: 5.6098  \n",
            "Epoch 92/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55.9618 - mae: 5.0533 \n",
            "Epoch 93/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.9285 - mae: 4.9374 \n",
            "Epoch 94/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.0395 - mae: 4.9856 \n",
            "Epoch 95/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 58.4961 - mae: 4.8549 \n",
            "Epoch 96/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.3192 - mae: 4.6129 \n",
            "Epoch 97/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 44.9699 - mae: 4.8545 \n",
            "Epoch 98/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 50.6468 - mae: 4.9904 \n",
            "Epoch 99/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 50.7622 - mae: 4.8525 \n",
            "Epoch 100/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 36.4771 - mae: 4.5233 \n",
            "Epoch 101/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 47.6444 - mae: 4.9241 \n",
            "Epoch 102/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 63.3185 - mae: 5.1907 \n",
            "Epoch 103/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 75.2976 - mae: 5.1044  \n",
            "Epoch 104/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 47.0839 - mae: 4.7272 \n",
            "Epoch 105/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 53.4054 - mae: 4.9008 \n",
            "Epoch 106/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 63.0789 - mae: 5.1395 \n",
            "Epoch 107/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 53.5247 - mae: 5.0471 \n",
            "Epoch 108/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 50.8186 - mae: 5.0572 \n",
            "Epoch 109/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 40.5895 - mae: 4.5626 \n",
            "Epoch 110/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.7568 - mae: 4.4763 \n",
            "Epoch 111/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 51.3560 - mae: 4.9136 \n",
            "Epoch 112/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.0119 - mae: 4.9472 \n",
            "Epoch 113/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.9588 - mae: 4.3879  \n",
            "Epoch 114/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.0984 - mae: 4.7750 \n",
            "Epoch 115/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.3100 - mae: 4.3635 \n",
            "Epoch 116/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55.8532 - mae: 4.5200 \n",
            "Epoch 117/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.5483 - mae: 4.9664 \n",
            "Epoch 118/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.8349 - mae: 4.6840  \n",
            "Epoch 119/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 73.5693 - mae: 5.0207  \n",
            "Epoch 120/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49.1551 - mae: 4.6114 \n",
            "Epoch 121/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.0403 - mae: 4.8241  \n",
            "Epoch 122/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49.3760 - mae: 4.7757 \n",
            "Epoch 123/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.8771 - mae: 4.5136 \n",
            "Epoch 124/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.4220 - mae: 4.6415 \n",
            "Epoch 125/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.0230 - mae: 4.7503 \n",
            "Epoch 126/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55.5089 - mae: 4.6343 \n",
            "Epoch 127/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.2517 - mae: 4.4044 \n",
            "Epoch 128/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.0138 - mae: 4.5428 \n",
            "Epoch 129/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.8423 - mae: 4.7211 \n",
            "Epoch 130/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.3765 - mae: 4.6584 \n",
            "Epoch 131/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.4268 - mae: 4.7648 \n",
            "Epoch 132/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.3819 - mae: 4.6033  \n",
            "Epoch 133/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.2464 - mae: 4.5153 \n",
            "Epoch 134/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.3996 - mae: 4.3465  \n",
            "Epoch 135/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.8122 - mae: 4.8111 \n",
            "Epoch 136/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.1272 - mae: 4.6179 \n",
            "Epoch 137/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.8000 - mae: 4.8975 \n",
            "Epoch 138/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.1279 - mae: 4.9485 \n",
            "Epoch 139/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 75.3727 - mae: 5.0529  \n",
            "Epoch 140/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 62.7132 - mae: 5.0045 \n",
            "Epoch 141/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 72.4154 - mae: 4.8371  \n",
            "Epoch 142/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55.2076 - mae: 4.5437  \n",
            "Epoch 143/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.6972 - mae: 4.6698 \n",
            "Epoch 144/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.5285 - mae: 4.5453 \n",
            "Epoch 145/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.9347 - mae: 4.4116 \n",
            "Epoch 146/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.3840 - mae: 4.9409  \n",
            "Epoch 147/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.9008 - mae: 4.6112 \n",
            "Epoch 148/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.7186 - mae: 4.8053 \n",
            "Epoch 149/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 69.5664 - mae: 4.8797  \n",
            "Epoch 150/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.7242 - mae: 4.3988 \n",
            "Epoch 151/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.9662 - mae: 4.4659 \n",
            "Epoch 152/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.7328 - mae: 4.7588 \n",
            "Epoch 153/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 46.1229 - mae: 4.5724  \n",
            "Epoch 154/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.3455 - mae: 4.5387 \n",
            "Epoch 155/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.4668 - mae: 4.5221  \n",
            "Epoch 156/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.6429 - mae: 4.3618 \n",
            "Epoch 157/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 65.9637 - mae: 4.8805 \n",
            "Epoch 158/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.9259 - mae: 4.2231 \n",
            "Epoch 159/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.2452 - mae: 4.5528 \n",
            "Epoch 160/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.1341 - mae: 4.1017 \n",
            "Epoch 161/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 46.5696 - mae: 4.5230 \n",
            "Epoch 162/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.7775 - mae: 4.4633 \n",
            "Epoch 163/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.0553 - mae: 4.3808 \n",
            "Epoch 164/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.5042 - mae: 4.5323 \n",
            "Epoch 165/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 74.6902 - mae: 5.1180  \n",
            "Epoch 166/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.2055 - mae: 4.7225  \n",
            "Epoch 167/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.4593 - mae: 4.3565 \n",
            "Epoch 168/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.0810 - mae: 4.5813 \n",
            "Epoch 169/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.2042 - mae: 4.2112  \n",
            "Epoch 170/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 46.1922 - mae: 4.4629 \n",
            "Epoch 171/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.8571 - mae: 4.2282 \n",
            "Epoch 172/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 75.7005 - mae: 4.9592  \n",
            "Epoch 173/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.8904 - mae: 4.5403  \n",
            "Epoch 174/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 64.2024 - mae: 4.7558 \n",
            "Epoch 175/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.3820 - mae: 4.5764 \n",
            "Epoch 176/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.5070 - mae: 4.2387 \n",
            "Epoch 177/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.6386 - mae: 4.3644  \n",
            "Epoch 178/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.9246 - mae: 4.3405 \n",
            "Epoch 179/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.8969 - mae: 4.1057 \n",
            "Epoch 180/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.1317 - mae: 4.6680 \n",
            "Epoch 181/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.1507 - mae: 4.5057 \n",
            "Epoch 182/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.5346 - mae: 4.4093  \n",
            "Epoch 183/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.5668 - mae: 4.6246 \n",
            "Epoch 184/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 57.2511 - mae: 4.7353  \n",
            "Epoch 185/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.7824 - mae: 4.3388 \n",
            "Epoch 186/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 71.0893 - mae: 4.7061 \n",
            "Epoch 187/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 52.1992 - mae: 4.6118  \n",
            "Epoch 188/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.0911 - mae: 4.3745  \n",
            "Epoch 189/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.1388 - mae: 3.9796 \n",
            "Epoch 190/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.4084 - mae: 4.4223 \n",
            "Epoch 191/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.9123 - mae: 4.4428 \n",
            "Epoch 192/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 46.9986 - mae: 4.6134\n",
            "Epoch 193/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 52.0012 - mae: 4.5673\n",
            "Epoch 194/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.2797 - mae: 4.2523 \n",
            "Epoch 195/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 72.7876 - mae: 4.9994  \n",
            "Epoch 196/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 66.9840 - mae: 4.6096  \n",
            "Epoch 197/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 52.3274 - mae: 4.6238 \n",
            "Epoch 198/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.6580 - mae: 4.3276 \n",
            "Epoch 199/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.2651 - mae: 4.2856 \n",
            "Epoch 200/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.1318 - mae: 4.2266 \n",
            "Epoch 201/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.7157 - mae: 4.5608 \n",
            "Epoch 202/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.2335 - mae: 4.2301 \n",
            "Epoch 203/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 64.8526 - mae: 4.4833  \n",
            "Epoch 204/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.2172 - mae: 4.3789 \n",
            "Epoch 205/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 40.8288 - mae: 4.4733 \n",
            "Epoch 206/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 44.0836 - mae: 4.5192 \n",
            "Epoch 207/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 69.1390 - mae: 4.7849  \n",
            "Epoch 208/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 50.3335 - mae: 4.4060 \n",
            "Epoch 209/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 41.2302 - mae: 4.2910 \n",
            "Epoch 210/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35.4449 - mae: 4.1054 \n",
            "Epoch 211/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 54.9136 - mae: 4.4563 \n",
            "Epoch 212/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.9666 - mae: 4.2194 \n",
            "Epoch 213/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.1903 - mae: 4.2223 \n",
            "Epoch 214/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 41.5017 - mae: 4.2538 \n",
            "Epoch 215/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 48.4975 - mae: 4.6119 \n",
            "Epoch 216/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 53.4425 - mae: 4.6585 \n",
            "Epoch 217/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 59.4815 - mae: 4.8403 \n",
            "Epoch 218/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55.9825 - mae: 4.4182 \n",
            "Epoch 219/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 43.8956 - mae: 4.3111 \n",
            "Epoch 220/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 46.2294 - mae: 4.2040 \n",
            "Epoch 221/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.7344 - mae: 4.2897 \n",
            "Epoch 222/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.0534 - mae: 4.3990  \n",
            "Epoch 223/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.0378 - mae: 4.3906 \n",
            "Epoch 224/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 46.0932 - mae: 4.4170 \n",
            "Epoch 225/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.8546 - mae: 4.1043 \n",
            "Epoch 226/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.4820 - mae: 4.1331  \n",
            "Epoch 227/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.2605 - mae: 4.1102 \n",
            "Epoch 228/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.6403 - mae: 4.5261 \n",
            "Epoch 229/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.2991 - mae: 4.1698 \n",
            "Epoch 230/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.9244 - mae: 3.9943 \n",
            "Epoch 231/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.3329 - mae: 4.4311 \n",
            "Epoch 232/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.0572 - mae: 4.3194 \n",
            "Epoch 233/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.5011 - mae: 4.5425 \n",
            "Epoch 234/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.1438 - mae: 4.3275 \n",
            "Epoch 235/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.7164 - mae: 4.1819 \n",
            "Epoch 236/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.0566 - mae: 4.1084 \n",
            "Epoch 237/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.8959 - mae: 4.0418 \n",
            "Epoch 238/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 69.2927 - mae: 4.7344  \n",
            "Epoch 239/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.6264 - mae: 4.1543  \n",
            "Epoch 240/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 76.2680 - mae: 4.9456  \n",
            "Epoch 241/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.8584 - mae: 4.6558 \n",
            "Epoch 242/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.3662 - mae: 4.4001 \n",
            "Epoch 243/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.5305 - mae: 4.3255 \n",
            "Epoch 244/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.0658 - mae: 4.3808 \n",
            "Epoch 245/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.2376 - mae: 4.1457 \n",
            "Epoch 246/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.2034 - mae: 4.3714 \n",
            "Epoch 247/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.9884 - mae: 4.6563 \n",
            "Epoch 248/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.1441 - mae: 4.1630 \n",
            "Epoch 249/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.8203 - mae: 4.2426 \n",
            "Epoch 250/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.3703 - mae: 4.6527 \n",
            "Epoch 251/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.6476 - mae: 4.3305 \n",
            "Epoch 252/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.0715 - mae: 4.2042  \n",
            "Epoch 253/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.1066 - mae: 4.2991 \n",
            "Epoch 254/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55.1916 - mae: 4.5998 \n",
            "Epoch 255/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 70.4405 - mae: 4.7067  \n",
            "Epoch 256/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.0875 - mae: 4.0661 \n",
            "Epoch 257/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.8144 - mae: 4.2699 \n",
            "Epoch 258/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55.7113 - mae: 4.5106 \n",
            "Epoch 259/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.0242 - mae: 4.1088 \n",
            "Epoch 260/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.5583 - mae: 4.1652 \n",
            "Epoch 261/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.1138 - mae: 4.1767 \n",
            "Epoch 262/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.4799 - mae: 4.1870 \n",
            "Epoch 263/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.2966 - mae: 4.2633 \n",
            "Epoch 264/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.4458 - mae: 4.4162 \n",
            "Epoch 265/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.3225 - mae: 4.2854 \n",
            "Epoch 266/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.7593 - mae: 4.4080 \n",
            "Epoch 267/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.0824 - mae: 4.1721 \n",
            "Epoch 268/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55.7993 - mae: 4.3647 \n",
            "Epoch 269/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.7998 - mae: 4.0542 \n",
            "Epoch 270/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.4174 - mae: 4.2462 \n",
            "Epoch 271/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.7645 - mae: 4.2189  \n",
            "Epoch 272/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 62.7562 - mae: 4.7161 \n",
            "Epoch 273/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 46.4637 - mae: 4.4535 \n",
            "Epoch 274/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.8733 - mae: 4.3021 \n",
            "Epoch 275/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.7745 - mae: 3.8713 \n",
            "Epoch 276/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.5313 - mae: 4.3536 \n",
            "Epoch 277/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.3517 - mae: 4.1877 \n",
            "Epoch 278/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.2260 - mae: 4.1707 \n",
            "Epoch 279/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 68.2845 - mae: 4.7133  \n",
            "Epoch 280/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.0488 - mae: 4.0912 \n",
            "Epoch 281/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.7374 - mae: 4.0434 \n",
            "Epoch 282/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.5778 - mae: 4.1810  \n",
            "Epoch 283/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.0396 - mae: 4.2991 \n",
            "Epoch 284/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.1533 - mae: 4.5277  \n",
            "Epoch 285/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.6385 - mae: 4.0837 \n",
            "Epoch 286/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.4409 - mae: 4.1172  \n",
            "Epoch 287/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.5011 - mae: 4.0641 \n",
            "Epoch 288/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.6508 - mae: 4.0537 \n",
            "Epoch 289/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.7089 - mae: 4.0806 \n",
            "Epoch 290/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.5663 - mae: 3.8791 \n",
            "Epoch 291/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.8531 - mae: 4.2050 \n",
            "Epoch 292/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.5716 - mae: 3.9197 \n",
            "Epoch 293/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 46.7834 - mae: 4.3420 \n",
            "Epoch 294/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.0983 - mae: 4.1801 \n",
            "Epoch 295/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.9892 - mae: 4.1753  \n",
            "Epoch 296/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.1552 - mae: 3.8674 \n",
            "Epoch 297/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.8337 - mae: 4.4390 \n",
            "Epoch 298/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.9880 - mae: 4.0045 \n",
            "Epoch 299/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 53.4676 - mae: 4.3768 \n",
            "Epoch 300/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.8753 - mae: 3.7930 \n"
          ]
        }
      ],
      "source": [
        "# Question 2  - 2 thru 6) ( Do not remove)\n",
        "from keras import optimizers\n",
        "\n",
        "# 2, 3, 4\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_dim=X.shape[1], activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# 5\n",
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# 6\n",
        "history = model.fit(X_trans, y, epochs=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbBeDUZVVKjX"
      },
      "source": [
        "# Evaluate the model\n",
        "Print out the mse and mae to compare to the Sci-kit learn for neural network to the Keras neural network.\n",
        "\n",
        "```\n",
        "X_tst_t = preprocessing_pipeline.transform(Xtest)\n",
        "md.evaluate(X_tst_t, y_test)\n",
        "\n",
        "```\n",
        "# Question 3\n",
        "Using the code above.\n",
        "1. Transform the X_test dataframe using the preprocessing_pipeline and assign to the X_test_trans.\n",
        "2. Evaluate the model using the X_test_trans and y_test.  Change md to model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "60-R6Cq_hPMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a0fe0c-2fc2-499c-cb84-00de696f18bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras Neural Network Results:\n",
            "MSE: 34.03763961791992\n",
            "MAE: 4.080772876739502\n"
          ]
        }
      ],
      "source": [
        "# Question 3 - 1 and 2)  (Do not remove)\n",
        "X_test_trans = preprocessing_pipeline.transform(X_test)\n",
        "mse, mae = model.evaluate(X_test_trans, y_test, verbose=0)\n",
        "print(\"Keras Neural Network Results:\")\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "BjWa-bdrytjv",
        "outputId": "66f3dcfa-d84f-45bd-a5b0-38dad280b2d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x787571ecaa90>]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNv3Ej1vYfEY"
      },
      "source": [
        "# Which model is better?\n",
        "Sci-kit Learn Neural Network or Keras Neural Network.  Answer 'sci-kit' or 'Keras'.\n",
        "\n",
        "# Question 4\n",
        "1.  Enter sci-kit or Keras in the variable ans below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "K1xI1JZAytno"
      },
      "outputs": [],
      "source": [
        "ans = 'Keras'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}